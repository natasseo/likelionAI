{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차 과제",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natasseo/likelionAI/blob/master/4%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ": 1943년 워랜 맥컬록과 월터 피츠가 처음으로 발표한 간소화된 뇌의 뉴런 개념으로 맥컬록-피츠 뉴런 (MCP)라 한다. 뉴런들은 뇌의 신경세포와 서로 연결되어 있으며 화학적, 전기적 신호를 처리하고 전달하는데 관여한다. 맥컬록과 피츠는 이러한 신경세포를 이진 출력을 내는 간단한 논리 회로로 표현했으며, 몇 년 후에 프랭크 로젠 블렛은 MCP 뉴런 모델을 기반으로 퍼셉트론 학습 개념을 발표하게 된다.\n",
        "\n",
        "### 퍼셉트론\n",
        ": 퍼셉트론에서 프랭크 로젠 블렛은 자동으로 최적의 가중치를 학습하는 알고리즘을 제안한다. 이 가중치는 뉴런의 출력 신호를 낼지 말지를 결정하기 위해 입력 특성에 곱하는 계수가 된다. 1949년 Donald O. Hebb는 인간 두뇌의 작용은 개별 신경세포에 의해서 이뤄지는 것이 아닌, 그들 간의 연결 강도로 정해진다는 연결주의를 주장하며 우리의 두뇌가 신경망으로 활동하고 있음을 설명했다. 이러한 이론에 자신의 이름을 붙여 헵의 학습 규칙이라 부른다. 이 규칙은 가장 오래되고 단순한 형태인데, 이 규칙은 만약 시냅스가 양쪽 뉴런이 동시에 또 반복적으로 활성화되었다면 그 뉴런 사이의 연결 강도가 강화된다는 관찰에 근거한다. 이러한 헵의 학습 규칙은 이후 신경망 모델들의 학습 규칙에 토대가 된다. 이러한 퍼셉트론을 간단하게 표현해보면 입력을 받아서 계산한 후 출력을 반환하는 구조로 나타낼 수 있는데, 사실 신경망은 뉴런이 여러 개 모여 레이어를 구성한 후, 이 레이어가 다시 모여 구성된 형태이다. 그리고 이 하나의 뉴런을 조금 더 자세하게 표현하면 가중치와 활성화 함수가 숨어있는 것을 확인할 수 있다. 이때 이 활성화 함수는 뉴런의 출력 값을 정하는 함수로서, 가장 간단한 형태의 뉴런은 입력에 가중치를 곱한 뒤, 활성화 함수를 취하면 출력 값을 얻을 수 있다. 이 뉴런에서 학습할 때 변하는 것은 가중치이다. 가중치는 처음에 초기화를 통해 무작위 값을 넣고, 학습 과정에서 점차 일정한 값으로 수렴한다. 학습이 잘 된다는 것은 좋은 가중치를 얻어 원하는 출력에 점점 가까워지는 값을 얻는 것이라 할 수 있다. 파이썬에서 시그모이드 함수를 사용할 때 가중치를 조절할 때 경사하강법을 쓸 수 있다. 가중치 갱신을 위해 학습률이라는 개념이 등장한다. 학습률은 가중치 조정을 위한 하이퍼파라미터이다. 편향은 의미 그대로 입력으로는 늘 한쪽으로 치우처진 고정 값이며, 입력으로 받은 값이 0인 경우에 아무것도 학습하지 못하는 것을 방지한다. 퍼셉트론을 잘 이해하기 위해서는 AND, OR, XOR 연산을 알아야 한다. 여기서 XOR은 간단하게 2개의 입력값이 서로 다를 때 참을 출력하게 된다. 퍼셉트론은 이러한 XOR연산에 대해 다양한 가중치를 바탕으로 학습을 진행해도 원하는 값으로 수렴하지 않는다. 이때 단층이 아닌, 다층 퍼셉트론을 활용하게 되면 문제가 해결된다. 1986년 \"explorations in the microstructure of cognition\"에서 은닉층을 활용하게 되면 선형 분류 판별선을 여러 개 그리는 효과를 얻음으로써 XOR문제를 해결할 수 있다고 밝혔다. 하지만 이 다층 퍼셉트론의 치명적인 약점은 바로 파라미터 개수가 많아지면서 적절한 가중치와 편향을 학습하는 것이 어렵다는 것이었는데, 제프리 힌튼은 역전파 알고리즘을 제시하며 문제를 해결한다.\n",
        "\n",
        "### 역전파\n",
        ": 1987년 Parallel Distributed Processing을 통해 역전파가 세상에 공개되었다. 신경망의 역전파는 그 이름에서도 알 수 있듯, 뉴런의 가중치를 효율적으로 조정하기 위하여, 거꾸로 무엇인가를 전파하는 방식이다. 즉 역전파는 출력 값과 지도 데이터 사이에 생기는 '오차'를 이용해 출력층에서 입력층 쪽으로 가중치를 조정하는 것이다. 이러한 역전파는 경사 하강법을 사용하는 것이기도 하다. 역전파는 손실 함수가 최솟값일 때의 가중치로 원래의 가중치를 조정해야 한다. 그래서 입력값 각각의 손실 함수 전체를 고려해야 한다. \n",
        "\n",
        "### 강화학습\n",
        ": 에이전트라는 존재가 환경과 상호작용하며, 이 환경에는 보상이라는 기준이 있어서 다양한 시행착오를 겪으며 보상을 최대화하는 방향으로 학습을 진행한다. 강화학습은 다양한 시행착오를 통해 학습이 가능하며, 비교적 명확한 보상을 설정할 수 있는 문제를 해결하는데 사용되고 있다. 강화 학습은 빠르게 발전을 거듭해 오면서 지금껏 인공지능으로 해결하기 힘들다고 생각한 많은 문제들을 해결해왔다. \n",
        "\n",
        "### 과적합\n",
        ": 학습 데이터를 과하게 학습(overfitting)하는 것을 뜻한다. 일반적으로 학습 데이터는 실제 데이터의 부분집합이므로 학습데이터에 대해서는 오차가 감소하지만 실제 데이터에 대해서는 오차가 증가하게 된다. [출처:위키백과](https://ko.wikipedia.org/wiki/%EA%B3%BC%EC%A0%81%ED%95%A9)\n",
        "\n",
        "### 차원의 저주\n",
        ": 훈련 데이터셋이 차원이 늘어남에 따라 특성 공간이 점점 희소해지는 현상이다. 이를 대비하기 위해 올바른 변수를 선택하고, 차원 축소 기법 등을 사용해야 한다.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhoQLPKtFYnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "ee016405-1372-4e64-a130-c53386c67fbf"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1],0,1)\n",
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1/(1+math.exp(-x))\n",
        "output = sigmoid(x*w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x * w)\n",
        "  error = y-output\n",
        "  w = w + x * 0.1 * error\n",
        "  if i % 100==99:\n",
        "    print(\"학습횟수:\", i, \"Error:\", error, \"예측결과:\", output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습횟수: 99 Error: -0.10010598284299604 예측결과: 0.10010598284299604\n",
            "학습횟수: 199 Error: -0.05178399422833116 예측결과: 0.05178399422833116\n",
            "학습횟수: 299 Error: -0.034590451977903586 예측결과: 0.034590451977903586\n",
            "학습횟수: 399 Error: -0.02588962752851373 예측결과: 0.02588962752851373\n",
            "학습횟수: 499 Error: -0.020658699939863617 예측결과: 0.020658699939863617\n",
            "학습횟수: 599 Error: -0.017174253993457355 예측결과: 0.017174253993457355\n",
            "학습횟수: 699 Error: -0.014689506449480992 예측결과: 0.014689506449480992\n",
            "학습횟수: 799 Error: -0.012829497265431342 예측결과: 0.012829497265431342\n",
            "학습횟수: 899 Error: -0.011385568271837804 예측결과: 0.011385568271837804\n",
            "학습횟수: 999 Error: -0.010232493309882492 예측결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1.6\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
      ]
    }
  ]
}